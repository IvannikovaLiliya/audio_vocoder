{   
    "model_name": "FreeV",
    "input_training_wav_list": "/Users/liliyaivannikova/Documents/vkr/pytorch_project/audio_vocoder/data/descr/training.txt",
    "input_validation_wav_list": "/Users/liliyaivannikova/Documents/vkr/pytorch_project/audio_vocoder/data/descr/validation.txt",
    "raw_wavfile_path": "/Users/liliyaivannikova/Documents/vkr/pytorch_project/audio_vocoder/data/wavs/",
    "test_input_wavs_dir":"/Users/liliyaivannikova/Documents/vkr/pytorch_project/audio_vocoder/data/descr/test.txt",
    "test_input_mels_dir":"./",
    "test_mel_load": 0,
    "test_output_dir": "/Users/liliyaivannikova/Documents/vkr/pytorch_project/research/istftnet/pretrained/pretrained/freev_v1",

    "batch_size": 16,
    "learning_rate": 0.0002,
    "adam_b1": 0.8,
    "adam_b2": 0.99,
    "lr_decay": 0.999,
    "seed": 1234,
    "training_steps": 1000000,
    "training_epochs": 3100,
    "stdout_interval": 500,
    "checkpoint_interval": 5000,
    "summary_interval": 500,
    "validation_interval": 5000,
    "max_to_keep": 5,
    "checkpoint_path": "./Experiments/LJSpeech/FreeV",
    "checkpoint_file_load": "/Users/liliyaivannikova/Documents/vkr/pytorch_project/research/istftnet/pretrained/pretrained/freev",
    "mrd_weight": 0.1,

    "mpd_reshapes": [2, 3, 5, 7, 11],
    "ASP_channel": 513,
    "ASP_resblock_kernel_sizes": [3,7,11],
    "ASP_resblock_dilation_sizes": [[1,3,5], [1,3,5], [1,3,5]],
    "ASP_input_conv_kernel_size": 7,
    "ASP_output_conv_kernel_size": 7,

    "PSP_channel": 512,
    "PSP_resblock_kernel_sizes": [3,7,11],
    "PSP_resblock_dilation_sizes": [[1,3,5], [1,3,5], [1,3,5]], 
    "PSP_input_conv_kernel_size": 7,
    "PSP_output_R_conv_kernel_size": 7,
    "PSP_output_I_conv_kernel_size": 7,

    "segment_size": 16384,
    "num_mels": 80,
    "n_fft": 1024,
    "hop_size": 256,
    "win_size": 1024,

    "sampling_rate": 22050,

    "fmin": 0,
    "fmax": 8000,
    "meloss": null,
    "num_workers": 4
}
